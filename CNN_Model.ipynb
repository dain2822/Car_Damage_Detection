{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3819 images belonging to 2 classes.\n",
      "Found 801 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kangdongwoo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 863ms/step - accuracy: 0.7381 - loss: 0.8993 - val_accuracy: 0.7041 - val_loss: 0.5512\n",
      "Epoch 2/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 3/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 835ms/step - accuracy: 0.7657 - loss: 0.5095 - val_accuracy: 0.7678 - val_loss: 0.5130\n",
      "Epoch 4/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 5/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 854ms/step - accuracy: 0.7852 - loss: 0.4909 - val_accuracy: 0.7978 - val_loss: 0.4806\n",
      "Epoch 6/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 7/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 847ms/step - accuracy: 0.7821 - loss: 0.4865 - val_accuracy: 0.8177 - val_loss: 0.4246\n",
      "Epoch 8/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 9/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 842ms/step - accuracy: 0.8011 - loss: 0.4498 - val_accuracy: 0.7878 - val_loss: 0.4809\n",
      "Epoch 10/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 11/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 853ms/step - accuracy: 0.8191 - loss: 0.4221 - val_accuracy: 0.8015 - val_loss: 0.4550\n",
      "Epoch 12/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 13/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 852ms/step - accuracy: 0.8496 - loss: 0.3820 - val_accuracy: 0.8327 - val_loss: 0.3976\n",
      "Epoch 14/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 15/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 858ms/step - accuracy: 0.8547 - loss: 0.3821 - val_accuracy: 0.8826 - val_loss: 0.3092\n",
      "Epoch 16/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 17/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 854ms/step - accuracy: 0.8415 - loss: 0.3768 - val_accuracy: 0.8764 - val_loss: 0.3027\n",
      "Epoch 18/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 19/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 863ms/step - accuracy: 0.8714 - loss: 0.3455 - val_accuracy: 0.8951 - val_loss: 0.2950\n",
      "Epoch 20/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 21/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 844ms/step - accuracy: 0.8665 - loss: 0.3376 - val_accuracy: 0.8777 - val_loss: 0.3080\n",
      "Epoch 22/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 23/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 847ms/step - accuracy: 0.8478 - loss: 0.3720 - val_accuracy: 0.8876 - val_loss: 0.2939\n",
      "Epoch 24/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 25/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 845ms/step - accuracy: 0.8680 - loss: 0.3201 - val_accuracy: 0.8989 - val_loss: 0.2663\n",
      "Epoch 26/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 27/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 833ms/step - accuracy: 0.8558 - loss: 0.3517 - val_accuracy: 0.8976 - val_loss: 0.2964\n",
      "Epoch 28/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 29/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 842ms/step - accuracy: 0.8687 - loss: 0.3365 - val_accuracy: 0.7928 - val_loss: 0.5425\n",
      "Epoch 30/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 31/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 833ms/step - accuracy: 0.8874 - loss: 0.2950 - val_accuracy: 0.8652 - val_loss: 0.3495\n",
      "Epoch 32/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 33/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 831ms/step - accuracy: 0.8741 - loss: 0.3043 - val_accuracy: 0.8614 - val_loss: 0.3630\n",
      "Epoch 34/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 35/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 825ms/step - accuracy: 0.9052 - loss: 0.2663 - val_accuracy: 0.9014 - val_loss: 0.2487\n",
      "Epoch 36/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 37/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 828ms/step - accuracy: 0.8806 - loss: 0.3147 - val_accuracy: 0.8951 - val_loss: 0.2627\n",
      "Epoch 38/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 39/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 832ms/step - accuracy: 0.9045 - loss: 0.2601 - val_accuracy: 0.8764 - val_loss: 0.3253\n",
      "Epoch 40/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 41/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 831ms/step - accuracy: 0.9036 - loss: 0.2640 - val_accuracy: 0.9126 - val_loss: 0.2708\n",
      "Epoch 42/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 43/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 811ms/step - accuracy: 0.9024 - loss: 0.2567 - val_accuracy: 0.9076 - val_loss: 0.2477\n",
      "Epoch 44/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 45/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 811ms/step - accuracy: 0.8949 - loss: 0.2712 - val_accuracy: 0.8976 - val_loss: 0.2575\n",
      "Epoch 46/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 47/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 808ms/step - accuracy: 0.9050 - loss: 0.2495 - val_accuracy: 0.9114 - val_loss: 0.2612\n",
      "Epoch 48/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 49/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 825ms/step - accuracy: 0.9004 - loss: 0.2598 - val_accuracy: 0.8964 - val_loss: 0.2664\n",
      "Epoch 50/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 51/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 817ms/step - accuracy: 0.9037 - loss: 0.2570 - val_accuracy: 0.9114 - val_loss: 0.2610\n",
      "Epoch 52/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 53/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 819ms/step - accuracy: 0.9019 - loss: 0.2737 - val_accuracy: 0.9114 - val_loss: 0.2348\n",
      "Epoch 54/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 55/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 821ms/step - accuracy: 0.8821 - loss: 0.2878 - val_accuracy: 0.8951 - val_loss: 0.2712\n",
      "Epoch 56/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 57/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 857ms/step - accuracy: 0.9108 - loss: 0.2362 - val_accuracy: 0.8989 - val_loss: 0.3030\n",
      "Epoch 58/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 59/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 865ms/step - accuracy: 0.9075 - loss: 0.2409 - val_accuracy: 0.9039 - val_loss: 0.2680\n",
      "Epoch 60/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 61/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 841ms/step - accuracy: 0.9167 - loss: 0.2344 - val_accuracy: 0.9213 - val_loss: 0.2288\n",
      "Epoch 62/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 63/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 829ms/step - accuracy: 0.9211 - loss: 0.2263 - val_accuracy: 0.9089 - val_loss: 0.2390\n",
      "Epoch 64/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 65/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 812ms/step - accuracy: 0.9126 - loss: 0.2378 - val_accuracy: 0.9014 - val_loss: 0.2480\n",
      "Epoch 66/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 67/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 813ms/step - accuracy: 0.9054 - loss: 0.2596 - val_accuracy: 0.9014 - val_loss: 0.2477\n",
      "Epoch 68/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 69/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 818ms/step - accuracy: 0.9154 - loss: 0.2387 - val_accuracy: 0.9064 - val_loss: 0.2405\n",
      "Epoch 70/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 71/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 812ms/step - accuracy: 0.9235 - loss: 0.2083 - val_accuracy: 0.9064 - val_loss: 0.2796\n",
      "Epoch 72/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 73/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 810ms/step - accuracy: 0.9339 - loss: 0.1860 - val_accuracy: 0.8926 - val_loss: 0.2880\n",
      "Epoch 74/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 75/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 814ms/step - accuracy: 0.9138 - loss: 0.2298 - val_accuracy: 0.9226 - val_loss: 0.2170\n",
      "Epoch 76/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 77/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 828ms/step - accuracy: 0.9296 - loss: 0.2000 - val_accuracy: 0.9238 - val_loss: 0.2046\n",
      "Epoch 78/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 79/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 819ms/step - accuracy: 0.9203 - loss: 0.2115 - val_accuracy: 0.9213 - val_loss: 0.2163\n",
      "Epoch 80/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 81/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 840ms/step - accuracy: 0.9337 - loss: 0.1994 - val_accuracy: 0.9139 - val_loss: 0.2311\n",
      "Epoch 82/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 83/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 988ms/step - accuracy: 0.9166 - loss: 0.2041 - val_accuracy: 0.9176 - val_loss: 0.2136\n",
      "Epoch 84/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 85/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 831ms/step - accuracy: 0.9247 - loss: 0.2204 - val_accuracy: 0.9201 - val_loss: 0.2372\n",
      "Epoch 86/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 87/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 845ms/step - accuracy: 0.9247 - loss: 0.2096 - val_accuracy: 0.9213 - val_loss: 0.2216\n",
      "Epoch 88/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 89/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 835ms/step - accuracy: 0.9155 - loss: 0.2261 - val_accuracy: 0.9189 - val_loss: 0.1988\n",
      "Epoch 90/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 91/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 833ms/step - accuracy: 0.9223 - loss: 0.2169 - val_accuracy: 0.9313 - val_loss: 0.1990\n",
      "Epoch 92/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 93/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 825ms/step - accuracy: 0.9251 - loss: 0.2033 - val_accuracy: 0.9139 - val_loss: 0.2391\n",
      "Epoch 94/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 95/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 828ms/step - accuracy: 0.9315 - loss: 0.1850 - val_accuracy: 0.8814 - val_loss: 0.3831\n",
      "Epoch 96/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 97/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 931ms/step - accuracy: 0.9259 - loss: 0.1889 - val_accuracy: 0.9201 - val_loss: 0.2366\n",
      "Epoch 98/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 99/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 940ms/step - accuracy: 0.9277 - loss: 0.1870 - val_accuracy: 0.9114 - val_loss: 0.3124\n",
      "Epoch 100/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 101/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 931ms/step - accuracy: 0.9213 - loss: 0.2005 - val_accuracy: 0.8926 - val_loss: 0.4372\n",
      "Epoch 102/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 103/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 935ms/step - accuracy: 0.9208 - loss: 0.2063 - val_accuracy: 0.9164 - val_loss: 0.2774\n",
      "Epoch 104/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 105/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 923ms/step - accuracy: 0.9231 - loss: 0.2000 - val_accuracy: 0.9263 - val_loss: 0.2383\n",
      "Epoch 106/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 107/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 925ms/step - accuracy: 0.9238 - loss: 0.2019 - val_accuracy: 0.9426 - val_loss: 0.1693\n",
      "Epoch 108/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 109/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 919ms/step - accuracy: 0.9372 - loss: 0.1767 - val_accuracy: 0.9114 - val_loss: 0.2363\n",
      "Epoch 110/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 111/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 920ms/step - accuracy: 0.9325 - loss: 0.1847 - val_accuracy: 0.9164 - val_loss: 0.2285\n",
      "Epoch 112/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 113/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 910ms/step - accuracy: 0.9266 - loss: 0.1958 - val_accuracy: 0.8826 - val_loss: 0.2715\n",
      "Epoch 114/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 115/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 856ms/step - accuracy: 0.9265 - loss: 0.1952 - val_accuracy: 0.8527 - val_loss: 0.4977\n",
      "Epoch 116/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 117/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 843ms/step - accuracy: 0.9464 - loss: 0.1587 - val_accuracy: 0.9201 - val_loss: 0.2287\n",
      "Epoch 118/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 119/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 844ms/step - accuracy: 0.9393 - loss: 0.1665 - val_accuracy: 0.9326 - val_loss: 0.2273\n",
      "Epoch 120/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 121/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 850ms/step - accuracy: 0.9344 - loss: 0.1842 - val_accuracy: 0.9176 - val_loss: 0.2365\n",
      "Epoch 122/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 123/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 834ms/step - accuracy: 0.9393 - loss: 0.1677 - val_accuracy: 0.9064 - val_loss: 0.3460\n",
      "Epoch 124/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 125/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 837ms/step - accuracy: 0.9394 - loss: 0.1808 - val_accuracy: 0.9251 - val_loss: 0.2465\n",
      "Epoch 126/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 127/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 853ms/step - accuracy: 0.9461 - loss: 0.1554 - val_accuracy: 0.9276 - val_loss: 0.2159\n",
      "Epoch 128/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 129/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 913ms/step - accuracy: 0.9334 - loss: 0.1865 - val_accuracy: 0.9388 - val_loss: 0.2007\n",
      "Epoch 130/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 131/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 897ms/step - accuracy: 0.9415 - loss: 0.1639 - val_accuracy: 0.9238 - val_loss: 0.2320\n",
      "Epoch 132/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 133/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 893ms/step - accuracy: 0.9403 - loss: 0.1604 - val_accuracy: 0.9426 - val_loss: 0.1859\n",
      "Epoch 134/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 135/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 872ms/step - accuracy: 0.9349 - loss: 0.1720 - val_accuracy: 0.9288 - val_loss: 0.2723\n",
      "Epoch 136/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 137/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 880ms/step - accuracy: 0.9458 - loss: 0.1593 - val_accuracy: 0.9201 - val_loss: 0.2957\n",
      "Epoch 138/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 139/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 884ms/step - accuracy: 0.9395 - loss: 0.1735 - val_accuracy: 0.9338 - val_loss: 0.1933\n",
      "Epoch 140/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 141/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 878ms/step - accuracy: 0.9449 - loss: 0.1533 - val_accuracy: 0.9276 - val_loss: 0.2368\n",
      "Epoch 142/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 143/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 881ms/step - accuracy: 0.9407 - loss: 0.1625 - val_accuracy: 0.9426 - val_loss: 0.1867\n",
      "Epoch 144/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 145/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 883ms/step - accuracy: 0.9368 - loss: 0.1802 - val_accuracy: 0.8901 - val_loss: 0.3515\n",
      "Epoch 146/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 147/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 893ms/step - accuracy: 0.9383 - loss: 0.1553 - val_accuracy: 0.9288 - val_loss: 0.2529\n",
      "Epoch 148/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 149/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 901ms/step - accuracy: 0.9352 - loss: 0.1769 - val_accuracy: 0.9363 - val_loss: 0.1882\n",
      "Epoch 150/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 151/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 888ms/step - accuracy: 0.9478 - loss: 0.1582 - val_accuracy: 0.9251 - val_loss: 0.2769\n",
      "Epoch 152/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 153/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 891ms/step - accuracy: 0.9330 - loss: 0.1804 - val_accuracy: 0.9076 - val_loss: 0.3210\n",
      "Epoch 154/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 155/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 890ms/step - accuracy: 0.9443 - loss: 0.1730 - val_accuracy: 0.9176 - val_loss: 0.2732\n",
      "Epoch 156/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 157/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 881ms/step - accuracy: 0.9498 - loss: 0.1449 - val_accuracy: 0.9313 - val_loss: 0.2376\n",
      "Epoch 158/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 159/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 894ms/step - accuracy: 0.9279 - loss: 0.1967 - val_accuracy: 0.9251 - val_loss: 0.2273\n",
      "Epoch 160/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 161/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 890ms/step - accuracy: 0.9471 - loss: 0.1445 - val_accuracy: 0.9363 - val_loss: 0.2124\n",
      "Epoch 162/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 163/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 958ms/step - accuracy: 0.9494 - loss: 0.1376 - val_accuracy: 0.9176 - val_loss: 0.2329\n",
      "Epoch 164/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 165/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 897ms/step - accuracy: 0.9486 - loss: 0.1542 - val_accuracy: 0.9114 - val_loss: 0.2570\n",
      "Epoch 166/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 167/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 854ms/step - accuracy: 0.9356 - loss: 0.1628 - val_accuracy: 0.9313 - val_loss: 0.2376\n",
      "Epoch 168/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 169/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 851ms/step - accuracy: 0.9543 - loss: 0.1373 - val_accuracy: 0.9238 - val_loss: 0.2197\n",
      "Epoch 170/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 171/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 857ms/step - accuracy: 0.9454 - loss: 0.1562 - val_accuracy: 0.9164 - val_loss: 0.2390\n",
      "Epoch 172/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 173/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 843ms/step - accuracy: 0.9392 - loss: 0.1631 - val_accuracy: 0.9238 - val_loss: 0.2546\n",
      "Epoch 174/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 175/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 841ms/step - accuracy: 0.9504 - loss: 0.1382 - val_accuracy: 0.9226 - val_loss: 0.2162\n",
      "Epoch 176/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 177/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 852ms/step - accuracy: 0.9440 - loss: 0.1486 - val_accuracy: 0.9313 - val_loss: 0.2264\n",
      "Epoch 178/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 179/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 852ms/step - accuracy: 0.9358 - loss: 0.1668 - val_accuracy: 0.9288 - val_loss: 0.2104\n",
      "Epoch 180/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 181/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 844ms/step - accuracy: 0.9512 - loss: 0.1480 - val_accuracy: 0.9351 - val_loss: 0.2073\n",
      "Epoch 182/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 183/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 846ms/step - accuracy: 0.9389 - loss: 0.1697 - val_accuracy: 0.9401 - val_loss: 0.1741\n",
      "Epoch 184/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 185/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 847ms/step - accuracy: 0.9504 - loss: 0.1384 - val_accuracy: 0.9313 - val_loss: 0.2019\n",
      "Epoch 186/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 187/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 834ms/step - accuracy: 0.9462 - loss: 0.1432 - val_accuracy: 0.9276 - val_loss: 0.1927\n",
      "Epoch 188/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 189/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 835ms/step - accuracy: 0.9517 - loss: 0.1260 - val_accuracy: 0.9363 - val_loss: 0.1899\n",
      "Epoch 190/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 191/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 833ms/step - accuracy: 0.9558 - loss: 0.1381 - val_accuracy: 0.9126 - val_loss: 0.2648\n",
      "Epoch 192/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 193/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 827ms/step - accuracy: 0.9510 - loss: 0.1345 - val_accuracy: 0.9276 - val_loss: 0.3426\n",
      "Epoch 194/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 195/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 833ms/step - accuracy: 0.9594 - loss: 0.1188 - val_accuracy: 0.9426 - val_loss: 0.2053\n",
      "Epoch 196/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 197/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 832ms/step - accuracy: 0.9469 - loss: 0.1323 - val_accuracy: 0.9426 - val_loss: 0.2584\n",
      "Epoch 198/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 199/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 848ms/step - accuracy: 0.9518 - loss: 0.1332 - val_accuracy: 0.9263 - val_loss: 0.2630\n",
      "Epoch 200/200\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir = 'car-damage-dataset/data1a/training'  # 학습 데이터 폴더 경로\n",
    "validation_dir = 'car-damage-dataset/data1a/validation'  # 검증 데이터 폴더 경로\n",
    "\n",
    "# ImageDataGenerator 설정\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# ImageDataGenerator에서 이미지 불러오기\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),  # 이미지 크기 256x256로 조정\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # 이진 분류\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(256, 256),  # 이미지 크기 256x256로 조정\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# 모델 설계\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),  # 은닉층 크기 설정\n",
    "    Dense(1, activation='sigmoid')  # 이진 분류를 위한 출력층\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=200,  # 에포크 수 설정\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('car_damage_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "KakaoTalk_20241114_153120613.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "KakaoTalk_20241114_153120613_01.jpg: 파손 (Damaged)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "KakaoTalk_20241114_153120613_02.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "KakaoTalk_20241114_153120613_03.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "KakaoTalk_20241114_153120613_04.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "KakaoTalk_20241114_153120613_05.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "KakaoTalk_20241114_153120613_06.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "KakaoTalk_20241114_153120613_07.jpg: 파손 (Damaged)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "KakaoTalk_20241114_153120613_08.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "KakaoTalk_20241114_153120613_09.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "KakaoTalk_20241114_153120613_10.jpg: 파손 (Damaged)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "KakaoTalk_20241114_153120613_11.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "KakaoTalk_20241114_153120613_12.jpg: 비파손 (Damage-free)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "KakaoTalk_20241114_153120613_13.jpg: 비파손 (Damage-free)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('../car_damage_detection_model.h5')\n",
    "\n",
    "# 예측할 이미지가 있는 폴더 경로\n",
    "img_dir = '../test_image'  # 예측할 이미지 폴더 경로\n",
    "\n",
    "# 이미지 파일 확장자 목록\n",
    "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "# 폴더 내 모든 이미지 파일에 대해 반복하며 예측\n",
    "for img_file in os.listdir(img_dir):\n",
    "    if img_file.lower().endswith(valid_extensions):  # 이미지 파일만 선택\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        try:\n",
    "            # 이미지 불러오기 및 전처리\n",
    "            img = image.load_img(img_path, target_size=(256, 256))  # 모델의 입력 크기에 맞게 조정\n",
    "            img_array = image.img_to_array(img) / 255.0  # 정규화 (0~1 범위)\n",
    "            img_array = np.expand_dims(img_array, axis=0)  # 배치 차원 추가 (1, 128, 128, 3)\n",
    "\n",
    "            # 모델 예측\n",
    "            prediction = model.predict(img_array)\n",
    "\n",
    "            predicted_prob = prediction[0][0]   \n",
    "            # 예측 결과 출력 (이진 분류)\n",
    "            if predicted_prob > 0.5:\n",
    "                print(f\"{img_file}: 비파손 (Damage-free)\")\n",
    "            else:\n",
    "                print(f\"{img_file}: 파손 (Damaged)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangdongwoo\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:3386: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('../car_damage_detection_model.h5')\n",
    "\n",
    "# 이미지 파일 확장자 목록\n",
    "valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "# 폴더 내 모든 이미지 파일에 대해 예측하는 함수\n",
    "def predict_folder(img_dir):\n",
    "    results = []\n",
    "    for img_file in os.listdir(img_dir):\n",
    "        if img_file.lower().endswith(valid_extensions):  # 이미지 파일만 선택\n",
    "            img_path = os.path.join(img_dir, img_file)\n",
    "            try:\n",
    "                # 이미지 불러오기 및 전처리\n",
    "                img = image.load_img(img_path, target_size=(256, 256))  # 모델의 입력 크기에 맞게 조정\n",
    "                img_array = image.img_to_array(img) / 255.0  # 정규화 (0~1 범위)\n",
    "                img_array = np.expand_dims(img_array, axis=0)  # 배치 차원 추가 (1, 128, 128, 3)\n",
    "\n",
    "                # 모델 예측\n",
    "                prediction = model.predict(img_array)\n",
    "                predicted_prob = prediction[0][0]\n",
    "\n",
    "                # 예측 결과 저장\n",
    "                if predicted_prob > 0.5:\n",
    "                    results.append({'filename': img_file, 'result': \"파손되지 않은 차량입니다.\"})\n",
    "                else:\n",
    "                    results.append({'filename': img_file, 'result': \"파손된 차량입니다.\"})\n",
    "            except Exception as e:\n",
    "                results.append({'filename': img_file, 'error': str(e)})\n",
    "    return results\n",
    "\n",
    "# Flask 앱 생성\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 예측을 위한 엔드포인트 정의\n",
    "@app.route('/predict_folder', methods=['POST'])\n",
    "def predict_folder_endpoint():\n",
    "    data = request.get_json()\n",
    "    img_dir = data.get('img_dir')\n",
    "\n",
    "    if img_dir and os.path.isdir(img_dir):\n",
    "        results = predict_folder(img_dir)\n",
    "        return jsonify({'results': results})\n",
    "    else:\n",
    "        return jsonify({'error': 'Invalid directory path provided.'}), 400\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
